---
title: Sim Experiment
date: today
format:
  html:
    embed-resources: false
    code-fold: true
    toc: true
    toc-location: left
engine: julia
execute: 
  cache: true
  warning: false
  error: false
julia:
  exeflags: ["--project"]
---

Run with multiple threads to speed it up [not done yet]


```{julia}
using StatsBase
using Statistics
using Plots
using Random
using CSV
using GLM
using LinearAlgebra
using HypothesisTests
using LaTeXStrings
using SpecialFunctions
using SummaryTables 
using StatsPlots
using Clustering
using DataFrames
using TidierData
using Revise
using ProductPartitionModels

include("simFunctions2.jl")
# set plot defaults
default(fillopacity = 0.5, lineopacity = 1.0)
```



# Simulation experiment

We utilized a monte carlo simulation to assess perfomance of the proposed method and compare to other methods.
Synthetic observations were generated based on a multi-level linear model in which observations add one outcome $Y$ and two sets of explanatory covariates $X_1$ and $X_2$.
4 clusters of equal sizes among 200 observations were simulated with the magnitude of the common effects equal to and the magnitude of the group interaction effects equal to 0.5.
Additionally, each observation was generated with a variance of 0.25. 
The mean effect assocaited with each covariate was the sum of a common effect (that was shared across all observations) and a group specific effect (which was only shared within a given data cluster).
For the given set of simulations the following table describes the common and group specific effects.

- Some of the group effects had same direction as common effect
  - results in locally linear curve
- Some of the group effects had opposite direction as common effect
  - results in Simpson paradox
  - much easier differentiate groups


Let $X_g$ be a dummy matrix codifying group membership.

$$
  \begin{aligned}
    Y_{shared} & = X_1\beta_{1, shared} + X_2\beta_{2, shared} \\ 
    Y_{group} & = X_1 (X_g\beta_{1, group}) + X_2 (X_g\beta_{2, group}) \\
    Y & = Y_{shared} + Y_{group} + \epsilon \\
    \text{All together} & \\
    Y & = X_1\beta_{1, shared} + X_2\beta_{2, shared} + X_1 (X_g\beta_{1, group}) + X_2 (X_g\beta_{2, group}) + \epsilon \\
    & = X_1(\beta_{1, shared} + (X_g\beta_{1, group})) + X_2(\beta_{2, shared} + (X_g\beta_{2, group}) + \epsilon \\
  \end{aligned}
$$

# 5 clusters

```{julia}
N = 200
nc =5 
variance = 0
interEffect = 3.0
common = 2.0
niters=2000
reps = 25
xdiff=0.25 
fractions = repeat([1/nc], nc)
groupEffects = [quantile(Normal(0, interEffect), i/(length(fractions) + 1)) for i in 1:length(fractions)]
simInfo = DataFrame(Dict(
  "Fraction" => fractions,
  "B1_shared" => common,
  "ge" => groupEffects,
  "B1_group" => common .+ groupEffects,
))
simple_table(simInfo)
```

```{julia}
#| label: fig-singleSimdist2
#| fig-cap: "Illustrations of simulated data."

df = simData(rng; N=N, fractions=fractions, variance=variance, interEffect=interEffect, common=common, plotSim = true, xdiff=xdiff, dims = 1)
```


The DPM and Mixture of DPM's models were both fit using a 1000 step MCMC with 500 burn-in steps and a thinned to every 5th observation of the MCMC.
After fitting the data with 4 clusters, the data was subsequently trimmed to 2 clusters and refit to assess model performance under less heterogeneous circumstances.
Each model was fit 100 times for each circumstance following a random seed using the Mersenne Twister random number generator with starting seed 0.
Results from a single simulation is shown in @fig-singleSim.

```{julia}
#| label: fig-singleSim2
#| fig-cap: "Illustrations of a single simulation fit."

fractions = repeat([1/nc], nc)
simExperiment(rng, N, fractions, variance, interEffect, common, true, niters, xdiff = xdiff, dims = 1)
```


```{julia}
#| label: fig-randIndex2
#| fig-cap: "Rand index for 2 and four clusters."

results = CSV.read("results/c5_N200_inter4.0_common3.0_xd0.0_v0.0.csv", DataFrame)

p1 = histogram([results.rind_Mix, results.rind_DPM, results.rind_K],
          opacity = 0.5,
          labels = ["PPMx-shared" "PPMx" "Kmean"],
          title = "2 cluster"
          )
# p2 = histogram([results.rind_Mix_2, results.rind_DPM_2, results.rind_K_2],
#           opacity = 0.5,
#           labels = ["PPMx-shared" "PPMx" "Kmean"],
#           title = "2 cluster"
#           )
p3 = histogram([results.rindMixoos, results.rind_DPMoos, results.rind_Koos],
          opacity = 0.5,
          labels = ["PPMx-shared" "PPMx" "Kmean"],
          title = "2 cluster (OOS)"
          )
xlims!(0, 1.1)
# p4 = histogram([results.rind_Mix_2oos, results.rind_DPM_2oos, results.rind_K_2oos],
#           opacity = 0.5,
#           labels = ["PPMx-shared" "PPMx" "Kmean"],
#           title = "2 cluster (OOS)"
#           )
plot(p1, p3, layout= [1,1], plot_title = "Rand index")
```

## Overall assessment
To assess overall model performance of each method, we characterized the root mean squared prediction error (RMSE) for bayesian methods we summarized this with the posterior median of the RMSE.
Additionally, we computed the proportion of observations lying within the 95\% predictive credible interval which we call the Bayesian p-value @fig-bayesPvalue.
We also considered the differentiation between the DPM and Mixture of DPM models with a two-tailed Kolmogorov-Smirnov test @fig-ksTest.


## Common effect inference
We assessed the estimation of common effects.

```{julia}
#| label: fig-meanBeta5
#| fig-cap: "Sample distribution of estimated common effect."


```

## Clustering and Prediction
Next, we compared the models ability to cluster and predict within the fit dataset. These were assess through the median posterior Rand index @fig-randIndex and the median posterior RMSE @fig-RMSE.



```{julia}
#| label: fig-modelAssess
#| fig-cap: "RMSE for 2 and four clusters."

p1 = histogram([results.meanBeta1 results.meanBetakclust1], label = ["PPMx-shared"  "Kmean"], opacity = 0.25, title = "Common effects", color = ["grey" "yellow"])
vline!([mean(results.meanBeta1) mean(results.meanBetakclust1)], label = nothing, linewidth = 4, color = ["grey" "yellow"], opacity = 0.5)
vline!([common], label = "true", linewidth = 4, color = :black)
p2 = histogram([results.midMix, results.midDPM, results.kmean_MSE],
          opacity = 0.33,
          labels = ["PPMx-shared" "PPMx" "Kmean"],
          title = "RMSE"
          )
# This is broken but has been fix in next round of sims
p3 = histogram([results.ncMix, results.ncDPM, results.ncK],
          opacity = 0.33,
          labels = ["PPMx-shared" "PPMx" "Kmean"],
          title = "Number of clusters"
          )
plot(p1, p2, p3, layout= [1,2], plot_title = "5 clusters")
```


# - [ ] 
# - [ ]



